{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['custom_license',\n",
       " 'metadata.readme',\n",
       " 'json_schema.txt',\n",
       " 'noncomm_use_subset',\n",
       " 'metadata.csv',\n",
       " 'CORD-19-research-challenge.zip',\n",
       " 'biorxiv_medrxiv',\n",
       " 'COVID.DATA.LIC.AGMT.pdf',\n",
       " 'comm_use_subset']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('data.nosync')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = []\n",
    "for dirpath, dirnames, filenames in os.walk('data.nosync'):\n",
    "    counts.append({dirpath: {'directories':len(dirnames), 'files':len(filenames)}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data.nosync > custom_license > custom_license > \u001b[94m\u001b[1mpdf_json\u001b[0m has \u001b[91m\u001b[1m23152 files\u001b[0m with size \u001b[36m2957.56 MB\u001b[0m\n",
      "data.nosync > comm_use_subset > comm_use_subset > \u001b[94m\u001b[1mpdf_json\u001b[0m has \u001b[91m\u001b[1m9365 files\u001b[0m with size \u001b[36m1274.93 MB\u001b[0m\n",
      "data.nosync > comm_use_subset > comm_use_subset > \u001b[94m\u001b[1mpmc_json\u001b[0m has \u001b[91m\u001b[1m8995 files\u001b[0m with size \u001b[36m1053.19 MB\u001b[0m\n",
      "data.nosync > custom_license > custom_license > \u001b[94m\u001b[1mpmc_json\u001b[0m has \u001b[91m\u001b[1m4773 files\u001b[0m with size \u001b[36m382.15 MB\u001b[0m\n",
      "data.nosync > noncomm_use_subset > noncomm_use_subset > \u001b[94m\u001b[1mpdf_json\u001b[0m has \u001b[91m\u001b[1m2377 files\u001b[0m with size \u001b[36m260.39 MB\u001b[0m\n",
      "data.nosync > noncomm_use_subset > noncomm_use_subset > \u001b[94m\u001b[1mpmc_json\u001b[0m has \u001b[91m\u001b[1m2093 files\u001b[0m with size \u001b[36m188.85 MB\u001b[0m\n",
      "data.nosync > biorxiv_medrxiv > biorxiv_medrxiv > \u001b[94m\u001b[1mpdf_json\u001b[0m has \u001b[91m\u001b[1m1342 files\u001b[0m with size \u001b[36m109.08 MB\u001b[0m\n",
      "\u001b[94m\u001b[1mdata.nosync\u001b[0m has \u001b[91m\u001b[1m5 files\u001b[0m with size \u001b[36m71.98 MB\u001b[0m\n",
      "\n",
      "\n",
      "With total size of \u001b[36m6.2981 GB\u001b[0m and \u001b[91m\u001b[1m52102 files\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "total_files = 0\n",
    "total_size = 0\n",
    "for i in sorted(counts, key = lambda x: -list(x.values())[0]['files']):\n",
    "    files = list(i.values())[0]['files']        \n",
    "    path = list(i.keys())[0]\n",
    "    size = sum(os.path.getsize(path+'/'+f) for f in os.listdir(path) if os.path.isfile(path+'/'+f))\n",
    "    total_size += size\n",
    "    total_files += files\n",
    "    \n",
    "    if files == 0:\n",
    "        continue\n",
    "    if len(path.split('/')) > 1:\n",
    "        pretty_path = '/'.join(path.split('/')[:-1])+'/\\033[94m\\033[1m'+path.split('/')[-1]+'\\033[0m'\n",
    "        pretty_path = pretty_path.replace('/',' > ')\n",
    "    else:\n",
    "        pretty_path = '\\033[94m\\033[1m'+path+'\\033[0m'\n",
    "    print(f\"{pretty_path} has \\033[91m\\033[1m{files} files\\033[0m with size \\033[36m{round(size/1000000, 2)} MB\\033[0m\")\n",
    "\n",
    "print(f'\\n\\nWith total size of \\033[36m{round(total_size/1000000000, 4)} GB\\033[0m and \\033[91m\\033[1m{total_files} files\\033[0m')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take sample from each to see if files follow same pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs = ['data.nosync/custom_license/custom_license/pdf_json/',\n",
    "    'data.nosync/custom_license/custom_license/pmc_json/',\n",
    "    'data.nosync/comm_use_subset/comm_use_subset/pdf_json/',\n",
    "    'data.nosync/comm_use_subset/comm_use_subset/pmc_json/',\n",
    "    'data.nosync/noncomm_use_subset/noncomm_use_subset/pdf_json/',\n",
    "    'data.nosync/noncomm_use_subset/noncomm_use_subset/pmc_json/']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "samp_files = []\n",
    "for i in dirs:\n",
    "    file = os.listdir(i)[0]\n",
    "    samp_files.append(json.loads(open(i+'/'+file, 'r').read()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['paper_id', 'metadata', 'abstract', 'body_text', 'bib_entries', 'ref_entries', 'back_matter'])\n",
      "dict_keys(['paper_id', 'metadata', 'body_text', 'ref_entries', 'back_matter', 'bib_entries'])\n",
      "dict_keys(['paper_id', 'metadata', 'abstract', 'body_text', 'bib_entries', 'ref_entries', 'back_matter'])\n",
      "dict_keys(['paper_id', 'metadata', 'body_text', 'ref_entries', 'back_matter', 'bib_entries'])\n",
      "dict_keys(['paper_id', 'metadata', 'abstract', 'body_text', 'bib_entries', 'ref_entries', 'back_matter'])\n",
      "dict_keys(['paper_id', 'metadata', 'body_text', 'ref_entries', 'back_matter', 'bib_entries'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[print(i.keys()) for i in samp_files]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All have body text, extract that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "samp_texts = []\n",
    "for i in samp_files:\n",
    "    try:\n",
    "        samp_texts.append('\\n'.join([j['text'] for j in i['body_text']]))\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(samp_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('\\n\\n'.join(samp_texts))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
